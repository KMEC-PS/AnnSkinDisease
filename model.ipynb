{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "\n",
    "# Step 1: Set up the paths to your image folders\n",
    "train_path = r\"../../archive/skin-disease-datasaet/train_set\"\n",
    "test_path = r\"../../archive/skin-disease-datasaet/test_set\"\n",
    "\n",
    "# Check if the paths exist\n",
    "if not os.path.exists(train_path) or not os.path.exists(test_path):\n",
    "    raise FileNotFoundError(\"Please check your dataset paths!\")\n",
    "\n",
    "# Step 2: Function to load and prepare images\n",
    "def load_images(folder_path, image_size=(64, 64)):\n",
    "    \"\"\"Load images from folders and prepare them for training.\"\"\"\n",
    "    images = []  # Will store all images\n",
    "    labels = []  # Will store corresponding labels\n",
    "    \n",
    "    # Go through each subfolder (each disease type)\n",
    "    for disease_name in os.listdir(folder_path):\n",
    "        disease_folder = os.path.join(folder_path, disease_name)\n",
    "        if os.path.isdir(disease_folder):\n",
    "            print(f\"Loading images for: {disease_name}\")\n",
    "            \n",
    "            # Load each image in the disease folder\n",
    "            for image_name in os.listdir(disease_folder):\n",
    "                image_path = os.path.join(disease_folder, image_name)\n",
    "                try:\n",
    "                    # Open, resize, and convert image to RGB\n",
    "                    image = Image.open(image_path)\n",
    "                    image = image.resize(image_size)\n",
    "                    image = image.convert('RGB')\n",
    "                    \n",
    "                    # Convert image to numpy array and add to our lists\n",
    "                    images.append(np.array(image))\n",
    "                    labels.append(disease_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Couldn't load image {image_name}: {e}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def transform(images):\n",
    "    return images.astype('float32') / 255.0\n",
    "# Step 3: Function to prepare data for training\n",
    "def prepare_data(images, labels):\n",
    "    \"\"\"Convert images and labels into the right format for training.\"\"\"\n",
    "    # Normalize pixel values to be between 0 and 1\n",
    "    X = transform(images)\n",
    "    \n",
    "    # Convert text labels to numbers\n",
    "    label_converter = LabelEncoder()\n",
    "    numeric_labels = label_converter.fit_transform(labels)\n",
    "    \n",
    "    # Convert to one-hot encoding (e.g., 2 -> [0,0,1,0,0])\n",
    "    num_classes = len(set(numeric_labels))\n",
    "    y = np.zeros((len(numeric_labels), num_classes))\n",
    "    y[np.arange(len(numeric_labels)), numeric_labels] = 1\n",
    "    \n",
    "    return X, y, label_converter\n",
    "\n",
    "# Step 4: Neural Network Class\n",
    "class MultilayerNeuralNetwork:\n",
    "    def __init__(self, layer_sizes=[],labels={},training=True):\n",
    "        \"\"\"\n",
    "        Initialize neural network with multiple layers.\n",
    "        layer_sizes: list of numbers representing the size of each layer\n",
    "        Example: [12288, 512, 256, 128, 7] for 3 hidden layers\n",
    "        \"\"\"\n",
    "        # Initialize weights and biases for each layer\n",
    "        self.weights = {}\n",
    "        self.biases = {}\n",
    "        self.layers = {}\n",
    "        self.activations = {}\n",
    "        self.labels=labels\n",
    "        \n",
    "        if(training == False):\n",
    "            with open(\"parameters.pickle\", \"rb\") as infile:\n",
    "                parameters = pickle.load(infile)\n",
    "                self.weights = parameters[0]\n",
    "                self.biases = parameters[1]\n",
    "                layer_sizes = self.layer_sizes = parameters[2]\n",
    "                self.labels = parameters[3]\n",
    "\n",
    "        self.num_layers = len(layer_sizes) - 1\n",
    "        \n",
    "        \n",
    "        # Create weights and biases for each layer\n",
    "        if(training):\n",
    "            for i in range(self.num_layers):\n",
    "                # He initialization for better training\n",
    "                self.weights[i] = np.random.randn(layer_sizes[i], layer_sizes[i+1]) * np.sqrt(2./layer_sizes[i])\n",
    "                self.biases[i] = np.zeros((1, layer_sizes[i+1]))\n",
    "            self.layer_sizes = layer_sizes\n",
    "            \n",
    "        # Storage for training history\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': []\n",
    "        }\n",
    "    \n",
    "    def relu(self, x):\n",
    "        \"\"\"Activation function: returns x if x > 0, else 0\"\"\"\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def relu_derivative(self, x):\n",
    "        \"\"\"Derivative of ReLU function\"\"\"\n",
    "        return (x > 0) * 1\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        \"\"\"Convert numbers to probabilities that sum to 1\"\"\"\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / exp_x.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"Forward pass through all layers\"\"\"\n",
    "        current_input = X\n",
    "        \n",
    "        # Pass through each layer except the last\n",
    "        for i in range(self.num_layers - 1):\n",
    "            # Compute layer output\n",
    "            self.layers[i] = np.dot(current_input, self.weights[i]) + self.biases[i]\n",
    "            # Apply ReLU activation\n",
    "            self.activations[i] = self.relu(self.layers[i])\n",
    "            current_input = self.activations[i]\n",
    "        \n",
    "        # Last layer with softmax\n",
    "        i = self.num_layers - 1\n",
    "        self.layers[i] = np.dot(current_input, self.weights[i]) + self.biases[i]\n",
    "        self.activations[i] = self.softmax(self.layers[i])\n",
    "        \n",
    "        return self.activations[i]\n",
    "    \n",
    "    def backward(self, X, y, learning_rate):\n",
    "        \"\"\"Backward pass to update weights\"\"\"\n",
    "        batch_size = X.shape[0]\n",
    "        \n",
    "        # Initialize gradients\n",
    "        dweights = {}\n",
    "        dbiases = {}\n",
    "        \n",
    "        # Output layer error\n",
    "        error = self.activations[self.num_layers-1] - y\n",
    "        \n",
    "        # Go through layers backwards\n",
    "        for i in range(self.num_layers-1, -1, -1):\n",
    "            # Calculate gradients for weights and biases\n",
    "            if i == 0:\n",
    "                dweights[i] = np.dot(X.T, error) / batch_size\n",
    "            else:\n",
    "                dweights[i] = np.dot(self.activations[i-1].T, error) / batch_size\n",
    "            dbiases[i] = np.sum(error, axis=0, keepdims=True) / batch_size\n",
    "            \n",
    "            # Calculate error for next layer\n",
    "            if i > 0:\n",
    "                error = np.dot(error, self.weights[i].T) * self.relu_derivative(self.layers[i-1])\n",
    "        \n",
    "        # Update weights and biases\n",
    "        for i in range(self.num_layers):\n",
    "            self.weights[i] -= learning_rate * dweights[i]\n",
    "            self.biases[i] -= learning_rate * dbiases[i]\n",
    "    \n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        \"\"\"Calculate the loss (how wrong the predictions are)\"\"\"\n",
    "        return -np.mean(y_true * np.log(y_pred + 1e-15))\n",
    "    \n",
    "    def compute_accuracy(self, y_true, y_pred):\n",
    "        \"\"\"Calculate the accuracy (percentage of correct predictions)\"\"\"\n",
    "        predicted_classes = np.argmax(y_pred, axis=1)\n",
    "        true_classes = np.argmax(y_true, axis=1)\n",
    "        return np.mean(predicted_classes == true_classes)\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs=50, batch_size=32, learning_rate=0.01):\n",
    "        \"\"\"Train the neural network\"\"\"\n",
    "        num_samples = len(X_train)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Shuffle the training data\n",
    "            indices = np.random.permutation(num_samples)\n",
    "            X_shuffled = X_train[indices]\n",
    "            y_shuffled = y_train[indices]\n",
    "            \n",
    "            # Train in batches\n",
    "            for i in range(0, num_samples, batch_size):\n",
    "                X_batch = X_shuffled[i:i + batch_size]\n",
    "                y_batch = y_shuffled[i:i + batch_size]\n",
    "                \n",
    "                # Forward and backward pass\n",
    "                self.forward(X_batch)\n",
    "                self.backward(X_batch, y_batch, learning_rate)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            train_pred = self.forward(X_train)\n",
    "            train_loss = self.compute_loss(y_train, train_pred)\n",
    "            train_acc = self.compute_accuracy(y_train, train_pred)\n",
    "            \n",
    "            val_pred = self.forward(X_val)\n",
    "            val_loss = self.compute_loss(y_val, val_pred)\n",
    "            val_acc = self.compute_accuracy(y_val, val_pred)\n",
    "            \n",
    "            # Store history\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "            \n",
    "            # Print progress\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "                print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "                print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "        parameters=[self.weights,self.biases,self.layer_sizes,self.labels]\n",
    "        print(\"parameters:\",parameters)\n",
    "        with open(\"parameters.pickle\", \"wb\") as outfile:\n",
    "            pickle.dump(parameters, outfile)\n",
    "            \n",
    "    \n",
    "    def plot_history(self):\n",
    "        \"\"\"Plot training history\"\"\"\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Plot loss\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.history['train_loss'], label='Training Loss')\n",
    "        plt.plot(self.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot accuracy\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.history['train_acc'], label='Training Accuracy')\n",
    "        plt.plot(self.history['val_acc'], label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def transform(self,output):\n",
    "        return self.labels[np.argmax(output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Step 5: Load and prepare the data\n",
    "    print(\"Loading training images...\")\n",
    "    train_images, train_labels = load_images(train_path)\n",
    "    print(\"Loading test images...\")\n",
    "    test_images, test_labels = load_images(test_path)\n",
    "\n",
    "    # Prepare the data\n",
    "    print(\"Preparing data for training...\")\n",
    "    X_train, y_train, label_converter = prepare_data(train_images, train_labels)\n",
    "    X_test, y_test, _ = prepare_data(test_images, test_labels)\n",
    "\n",
    "    # Flatten the images\n",
    "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "    # Step 6: Create and train the model\n",
    "    input_size = X_train_flat.shape[1]  # Number of pixels in each image\n",
    "    output_size = len(set(train_labels))  # Number of disease classes\n",
    "\n",
    "    # Define the size of each layer\n",
    "    layer_sizes = [\n",
    "        input_size,    # Input layer\n",
    "        512,           # First hidden layer\n",
    "        256,           # Second hidden layer\n",
    "        128,           # Third hidden layer\n",
    "        output_size    # Output layer\n",
    "    ]\n",
    "        # Print class labels\n",
    "    label_index = {}\n",
    "    print(\"\\nDisease Classes:\")\n",
    "    for i, label in enumerate(label_converter.classes_):\n",
    "        print(f\"{i}: {label}\")\n",
    "        label_index[i] = label\n",
    "\n",
    "    print(\"Creating neural network...\")\n",
    "    model = MultilayerNeuralNetwork(layer_sizes,labels=label_index)\n",
    "    print(\"Starting training...\")\n",
    "    model.train(\n",
    "        X_train_flat, y_train,\n",
    "        X_test_flat, y_test,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        learning_rate=0.01\n",
    "    )\n",
    "\n",
    "    # Plot the training history\n",
    "    model.plot_history()\n",
    "\n",
    "    # Final evaluation\n",
    "    final_predictions = model.forward(X_test_flat)\n",
    "    final_accuracy = model.compute_accuracy(y_test, final_predictions)\n",
    "    print(f\"\\nFinal Test Accuracy: {final_accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    processed_image = transform(image)\n",
    "    input = processed_image.reshape(1, -1)\n",
    "    model = MultilayerNeuralNetwork(training=False)\n",
    "    return model.transform(model.forward(input))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
